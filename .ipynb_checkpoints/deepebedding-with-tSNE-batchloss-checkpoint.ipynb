{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "train_mnist = loadmat('mnist_train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train_mnist['train_X']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_mnist['train_labels']\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute symmetric joint probabilities in the original high-dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Hbeta(D, beta):\n",
    "    P = np.exp(-D * beta)\n",
    "    sumP = np.sum(P)\n",
    "    H = np.log(sumP) + beta * np.sum(np.multiply(D, P)) / sumP\n",
    "    P = P / sumP\n",
    "    return H, P\n",
    "\n",
    "def x2p(X, u=15, tol=1e-4, print_iter=2500, max_tries=50, verbose=0):\n",
    "    # Initialize some variables\n",
    "    n = X.shape[0]                     # number of instances\n",
    "    P = np.zeros((n, n))               # empty probability matrix\n",
    "    beta = np.ones(n)                  # empty precision vector\n",
    "    logU = np.log(u)                   # log of perplexity (= entropy)\n",
    "    \n",
    "    # Compute pairwise distances\n",
    "    if verbose > 0: print('Computing pairwise distances...')\n",
    "    sum_X = np.sum(np.square(X), axis=1)\n",
    "    # note: translating sum_X' from matlab to numpy means using reshape to add a dimension\n",
    "    D = sum_X + sum_X[:,None] + -2 * X.dot(X.T)\n",
    "\n",
    "    # Run over all datapoints\n",
    "    if verbose > 0: print('Computing P-values...')\n",
    "    for i in range(n):\n",
    "        \n",
    "        if verbose > 1 and print_iter and i % print_iter == 0:\n",
    "            print('Computed P-values {} of {} datapoints...'.format(i, n))\n",
    "        \n",
    "        # Set minimum and maximum values for precision\n",
    "        betamin = float('-inf')\n",
    "        betamax = float('+inf')\n",
    "        \n",
    "        # Compute the Gaussian kernel and entropy for the current precision\n",
    "        indices = np.concatenate((np.arange(0, i), np.arange(i + 1, n)))\n",
    "        Di = D[i, indices]\n",
    "        H, thisP = Hbeta(Di, beta[i])\n",
    "        \n",
    "        # Evaluate whether the perplexity is within tolerance\n",
    "        Hdiff = H - logU\n",
    "        tries = 0\n",
    "        while abs(Hdiff) > tol and tries < max_tries:\n",
    "            \n",
    "            # If not, increase or decrease precision\n",
    "            if Hdiff > 0:\n",
    "                betamin = beta[i]\n",
    "                if np.isinf(betamax):\n",
    "                    beta[i] *= 2\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamax) / 2\n",
    "            else:\n",
    "                betamax = beta[i]\n",
    "                if np.isinf(betamin):\n",
    "                    beta[i] /= 2\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamin) / 2\n",
    "            \n",
    "            # Recompute the values\n",
    "            H, thisP = Hbeta(Di, beta[i])\n",
    "            Hdiff = H - logU\n",
    "            tries += 1\n",
    "        \n",
    "        # Set the final row of P\n",
    "        P[i, indices] = thisP\n",
    "        \n",
    "    if verbose > 0: \n",
    "        print('Mean value of sigma: {}'.format(np.mean(np.sqrt(1 / beta))))\n",
    "        print('Minimum value of sigma: {}'.format(np.min(np.sqrt(1 / beta))))\n",
    "        print('Maximum value of sigma: {}'.format(np.max(np.sqrt(1 / beta))))\n",
    "    \n",
    "    return P, beta\n",
    "\n",
    "def compute_joint_probabilities(samples, batch_size=5000, d=2, perplexity=30, tol=1e-5, verbose=0):\n",
    "    v = d - 1\n",
    "    \n",
    "    # Initialize some variables\n",
    "    n = samples.shape[0]\n",
    "    batch_size = min(batch_size, n)\n",
    "    \n",
    "    # Precompute joint probabilities for all batches\n",
    "    if verbose > 0: print('Precomputing P-values...')\n",
    "    batch_count = int(n / batch_size)\n",
    "    P = np.zeros((batch_count, batch_size, batch_size))\n",
    "    for i, start in enumerate(range(0, n - batch_size + 1, batch_size)):   \n",
    "        curX = samples[start:start+batch_size]                   # select batch\n",
    "        P[i], beta = x2p(curX, perplexity, tol, verbose=verbose) # compute affinities using fixed perplexity\n",
    "        P[i][np.isnan(P[i])] = 0                                 # make sure we don't have NaN's\n",
    "        P[i] = (P[i] + P[i].T) # / 2                             # make symmetric\n",
    "        P[i] = P[i] / P[i].sum()                                 # obtain estimation of joint probabilities\n",
    "        P[i] = np.maximum(P[i], np.finfo(P[i].dtype).eps)\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "P = compute_joint_probabilities(data, batch_size=batch_size, verbose=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 5000, 5000)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('P.npy', P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D_in, fc1, fc2, fc3, D_out = 784, 500, 500, 2000, 3\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, fc1), torch.nn.ReLU(),\n",
    "    torch.nn.Linear(fc1, fc2), torch.nn.ReLU(),\n",
    "    torch.nn.Linear(fc2, fc3), torch.nn.ReLU(),\n",
    "    torch.nn.Linear(fc3, D_out)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define t-SNE loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tsne_loss(P, activations):\n",
    "    n = activations.size(0)\n",
    "    alpha = 1\n",
    "    eps = 1e-7\n",
    "    sum_act = torch.sum(torch.pow(activations, 2), 1)\n",
    "    Q = sum_act + sum_act.view([-1, 1]) - \\\n",
    "    2 * torch.matmul(activations, torch.transpose(activations, 0, 1))\n",
    "    Q = Q / alpha\n",
    "    Q = torch.pow(1 + Q, -(alpha + 1) / 2)\n",
    "    zero_dgnl_mat = autograd.Variable(1 - torch.eye(n), requires_grad=False)\n",
    "    Q = Q * zero_dgnl_mat\n",
    "    Q = Q / torch.sum(Q)\n",
    "    Q = torch.clamp(Q, min=eps)\n",
    "    C = torch.log((P + eps) / (Q + eps))\n",
    "    C = torch.sum(P * C)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare mini-batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyMNISTDataset(object):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "P = P.reshape(data.shape[0], -1)\n",
    "dataset = MyMNISTDataset(data, P)\n",
    "data_loader = DataLoader(dataset, batch_size=5000, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "torch.addmm received an invalid combination of arguments - got (int, torch.FloatTensor, int, torch.DoubleTensor, torch.FloatTensor, out=torch.FloatTensor), but expected one of:\n * (torch.FloatTensor source, torch.FloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n * (torch.FloatTensor source, torch.SparseFloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n * (float beta, torch.FloatTensor source, torch.FloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n * (torch.FloatTensor source, float alpha, torch.FloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n * (float beta, torch.FloatTensor source, torch.SparseFloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n * (torch.FloatTensor source, float alpha, torch.SparseFloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n * (float beta, torch.FloatTensor source, float alpha, torch.FloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.DoubleTensor\u001b[0m, \u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mout=torch.FloatTensor\u001b[0m)\n * (float beta, torch.FloatTensor source, float alpha, torch.SparseFloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.DoubleTensor\u001b[0m, \u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mout=torch.FloatTensor\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-3d97f5022017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hxiong/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hxiong/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hxiong/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hxiong/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hxiong/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hxiong/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36maddmm\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAddmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hxiong/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hxiong/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return torch.addmm(alpha, add_matrix, beta,\n\u001b[0;32m---> 26\u001b[0;31m                            matrix1, matrix2, out=output)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.addmm received an invalid combination of arguments - got (int, torch.FloatTensor, int, torch.DoubleTensor, torch.FloatTensor, out=torch.FloatTensor), but expected one of:\n * (torch.FloatTensor source, torch.FloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n * (torch.FloatTensor source, torch.SparseFloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n * (float beta, torch.FloatTensor source, torch.FloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n * (torch.FloatTensor source, float alpha, torch.FloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n * (float beta, torch.FloatTensor source, torch.SparseFloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n * (torch.FloatTensor source, float alpha, torch.SparseFloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n * (float beta, torch.FloatTensor source, float alpha, torch.FloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.DoubleTensor\u001b[0m, \u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mout=torch.FloatTensor\u001b[0m)\n * (float beta, torch.FloatTensor source, float alpha, torch.SparseFloatTensor mat1, torch.FloatTensor mat2, *, torch.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.DoubleTensor\u001b[0m, \u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mout=torch.FloatTensor\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "true_P = autograd.Variable(torch.Tensor(P), requires_grad=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "for epoch in range(100):  \n",
    "    for i, batch in enumerate(data_loader):\n",
    "        x, y = batch\n",
    "        x_var = autograd.Variable(x, typerequires_grad=False)\n",
    "        y_var = autograd.Variable(y, requires_grad=False)\n",
    "        y_pred = model(x_var)\n",
    "        loss = tsne_loss(y_var, y_pred)\n",
    "        print(epoch, i, loss.data[0])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visulization the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    pass\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"864pt\" height=\"464pt\"\n",
       " viewBox=\"0.00 0.00 864.00 463.96\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.789044 0.789044) rotate(0) translate(4 584)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-584 1091,-584 1091,4 -4,4\"/>\n",
       "<!-- 4728544272 -->\n",
       "<g id=\"node1\" class=\"node\"><title>4728544272</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"901.979,-20 798.021,-20 798.021,-0 901.979,-0 901.979,-20\"/>\n",
       "<text text-anchor=\"middle\" x=\"850\" y=\"-6.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 4631143928 -->\n",
       "<g id=\"node2\" class=\"node\"><title>4631143928</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"644,-90 590,-90 590,-56 644,-56 644,-90\"/>\n",
       "<text text-anchor=\"middle\" x=\"617\" y=\"-62.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (3)</text>\n",
       "</g>\n",
       "<!-- 4631143928&#45;&gt;4728544272 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>4631143928&#45;&gt;4728544272</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M644.301,-59.2113C647.207,-58.0472 650.145,-56.9506 653,-56 697.247,-41.2684 748.659,-29.7026 787.865,-21.9869\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"788.661,-25.3978 797.813,-20.0599 787.33,-18.5255 788.661,-25.3978\"/>\n",
       "</g>\n",
       "<!-- 4728624568 -->\n",
       "<g id=\"node3\" class=\"node\"><title>4728624568</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"775.801,-83 662.199,-83 662.199,-63 775.801,-63 775.801,-83\"/>\n",
       "<text text-anchor=\"middle\" x=\"719\" y=\"-69.4\" font-family=\"Times,serif\" font-size=\"12.00\">ThresholdBackward</text>\n",
       "</g>\n",
       "<!-- 4728624568&#45;&gt;4728544272 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>4728624568&#45;&gt;4728544272</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M738.33,-62.9992C760.291,-52.7727 796.344,-35.985 821.525,-24.2595\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"823.003,-27.4319 830.591,-20.0377 820.048,-21.0861 823.003,-27.4319\"/>\n",
       "</g>\n",
       "<!-- 4728624104 -->\n",
       "<g id=\"node4\" class=\"node\"><title>4728624104</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"678.979,-153 575.021,-153 575.021,-133 678.979,-133 678.979,-153\"/>\n",
       "<text text-anchor=\"middle\" x=\"627\" y=\"-139.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 4728624104&#45;&gt;4728624568 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>4728624104&#45;&gt;4728624568</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M639.408,-132.829C654.581,-121.614 680.478,-102.473 698.599,-89.079\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"700.828,-91.7841 706.789,-83.0255 696.667,-86.1548 700.828,-91.7841\"/>\n",
       "</g>\n",
       "<!-- 4631142920 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4631142920</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"421,-230 367,-230 367,-196 421,-196 421,-230\"/>\n",
       "<text text-anchor=\"middle\" x=\"394\" y=\"-202.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (2000)</text>\n",
       "</g>\n",
       "<!-- 4631142920&#45;&gt;4728624104 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>4631142920&#45;&gt;4728624104</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M421.334,-199.309C424.235,-198.126 427.161,-196.998 430,-196 478.297,-179.016 534.953,-164.615 575.077,-155.305\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"575.943,-158.698 584.907,-153.05 574.378,-151.875 575.943,-158.698\"/>\n",
       "</g>\n",
       "<!-- 4728624336 -->\n",
       "<g id=\"node6\" class=\"node\"><title>4728624336</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"552.801,-223 439.199,-223 439.199,-203 552.801,-203 552.801,-223\"/>\n",
       "<text text-anchor=\"middle\" x=\"496\" y=\"-209.4\" font-family=\"Times,serif\" font-size=\"12.00\">ThresholdBackward</text>\n",
       "</g>\n",
       "<!-- 4728624336&#45;&gt;4728624104 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>4728624336&#45;&gt;4728624104</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M513.396,-202.97C535.711,-191.387 574.628,-171.186 600.603,-157.702\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"602.269,-160.781 609.532,-153.067 599.044,-154.568 602.269,-160.781\"/>\n",
       "</g>\n",
       "<!-- 4728625264 -->\n",
       "<g id=\"node7\" class=\"node\"><title>4728625264</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"457.979,-293 354.021,-293 354.021,-273 457.979,-273 457.979,-293\"/>\n",
       "<text text-anchor=\"middle\" x=\"406\" y=\"-279.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 4728625264&#45;&gt;4728624336 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>4728625264&#45;&gt;4728624336</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M418.138,-272.829C432.982,-261.614 458.316,-242.473 476.043,-229.079\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"478.186,-231.846 484.055,-223.025 473.966,-226.261 478.186,-231.846\"/>\n",
       "</g>\n",
       "<!-- 4631144040 -->\n",
       "<g id=\"node8\" class=\"node\"><title>4631144040</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"200,-370 146,-370 146,-336 200,-336 200,-370\"/>\n",
       "<text text-anchor=\"middle\" x=\"173\" y=\"-342.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (500)</text>\n",
       "</g>\n",
       "<!-- 4631144040&#45;&gt;4728625264 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>4631144040&#45;&gt;4728625264</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M200.334,-339.309C203.235,-338.126 206.161,-336.998 209,-336 257.297,-319.016 313.953,-304.615 354.077,-295.305\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"354.943,-298.698 363.907,-293.05 353.378,-291.875 354.943,-298.698\"/>\n",
       "</g>\n",
       "<!-- 4728625728 -->\n",
       "<g id=\"node9\" class=\"node\"><title>4728625728</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"331.801,-363 218.199,-363 218.199,-343 331.801,-343 331.801,-363\"/>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-349.4\" font-family=\"Times,serif\" font-size=\"12.00\">ThresholdBackward</text>\n",
       "</g>\n",
       "<!-- 4728625728&#45;&gt;4728625264 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>4728625728&#45;&gt;4728625264</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M292.396,-342.97C314.711,-331.387 353.628,-311.186 379.603,-297.702\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"381.269,-300.781 388.532,-293.067 378.044,-294.568 381.269,-300.781\"/>\n",
       "</g>\n",
       "<!-- 4728624800 -->\n",
       "<g id=\"node10\" class=\"node\"><title>4728624800</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"237.979,-433 134.021,-433 134.021,-413 237.979,-413 237.979,-433\"/>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-419.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 4728624800&#45;&gt;4728625728 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>4728624800&#45;&gt;4728625728</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198.003,-412.829C212.549,-401.716 237.28,-382.82 254.784,-369.446\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"257.366,-371.878 263.187,-363.025 253.116,-366.316 257.366,-371.878\"/>\n",
       "</g>\n",
       "<!-- 4631143144 -->\n",
       "<g id=\"node11\" class=\"node\"><title>4631143144</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-510 0,-510 0,-476 54,-476 54,-510\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-482.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (500)</text>\n",
       "</g>\n",
       "<!-- 4631143144&#45;&gt;4728624800 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>4631143144&#45;&gt;4728624800</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.1035,-479.891C57.1019,-478.57 60.1135,-477.251 63,-476 94.1718,-462.485 129.962,-447.403 154.868,-436.977\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.299,-440.172 164.175,-433.086 153.598,-433.714 156.299,-440.172\"/>\n",
       "</g>\n",
       "<!-- 4728625032 -->\n",
       "<g id=\"node12\" class=\"node\"><title>4728625032</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"185.548,-503 72.4522,-503 72.4522,-483 185.548,-483 185.548,-503\"/>\n",
       "<text text-anchor=\"middle\" x=\"129\" y=\"-489.4\" font-family=\"Times,serif\" font-size=\"12.00\">TransposeBackward</text>\n",
       "</g>\n",
       "<!-- 4728625032&#45;&gt;4728624800 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>4728625032&#45;&gt;4728624800</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M136.687,-482.829C145.661,-472.124 160.688,-454.196 171.801,-440.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"174.693,-442.938 178.435,-433.025 169.328,-438.441 174.693,-442.938\"/>\n",
       "</g>\n",
       "<!-- 4631145496 -->\n",
       "<g id=\"node13\" class=\"node\"><title>4631145496</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"163.492,-580 94.5078,-580 94.5078,-546 163.492,-546 163.492,-580\"/>\n",
       "<text text-anchor=\"middle\" x=\"129\" y=\"-552.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (500, 784)</text>\n",
       "</g>\n",
       "<!-- 4631145496&#45;&gt;4728625032 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>4631145496&#45;&gt;4728625032</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M129,-545.885C129,-536.079 129,-523.497 129,-513.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"132.5,-513.111 129,-503.111 125.5,-513.111 132.5,-513.111\"/>\n",
       "</g>\n",
       "<!-- 4545235848 -->\n",
       "<g id=\"node14\" class=\"node\"><title>4545235848</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"281.992,-503 204.008,-503 204.008,-483 281.992,-483 281.992,-503\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-489.4\" font-family=\"Times,serif\" font-size=\"12.00\">(60000, 784)</text>\n",
       "</g>\n",
       "<!-- 4545235848&#45;&gt;4728624800 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>4545235848&#45;&gt;4728624800</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M235.313,-482.829C226.339,-472.124 211.312,-454.196 200.199,-440.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"202.672,-438.441 193.565,-433.025 197.307,-442.938 202.672,-438.441\"/>\n",
       "</g>\n",
       "<!-- 4545236552 -->\n",
       "<g id=\"node15\" class=\"node\"><title>4545236552</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"365.992,-503 300.008,-503 300.008,-483 365.992,-483 365.992,-503\"/>\n",
       "<text text-anchor=\"middle\" x=\"333\" y=\"-489.4\" font-family=\"Times,serif\" font-size=\"12.00\">(784, 500)</text>\n",
       "</g>\n",
       "<!-- 4545236552&#45;&gt;4728624800 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>4545236552&#45;&gt;4728624800</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M313.48,-482.97C288.219,-471.285 244.001,-450.831 214.858,-437.349\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.147,-434.089 205.601,-433.067 213.208,-440.442 216.147,-434.089\"/>\n",
       "</g>\n",
       "<!-- 4545233864 -->\n",
       "<g id=\"node16\" class=\"node\"><title>4545233864</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"333.992,-433 256.008,-433 256.008,-413 333.992,-413 333.992,-433\"/>\n",
       "<text text-anchor=\"middle\" x=\"295\" y=\"-419.4\" font-family=\"Times,serif\" font-size=\"12.00\">(60000, 500)</text>\n",
       "</g>\n",
       "<!-- 4545233864&#45;&gt;4728625728 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>4545233864&#45;&gt;4728625728</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M292.303,-412.829C289.304,-402.633 284.379,-385.887 280.548,-372.864\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"283.834,-371.632 277.655,-363.025 277.119,-373.607 283.834,-371.632\"/>\n",
       "</g>\n",
       "<!-- 4728625496 -->\n",
       "<g id=\"node17\" class=\"node\"><title>4728625496</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"462.548,-363 349.452,-363 349.452,-343 462.548,-343 462.548,-363\"/>\n",
       "<text text-anchor=\"middle\" x=\"406\" y=\"-349.4\" font-family=\"Times,serif\" font-size=\"12.00\">TransposeBackward</text>\n",
       "</g>\n",
       "<!-- 4728625496&#45;&gt;4728625264 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>4728625496&#45;&gt;4728625264</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M406,-342.829C406,-332.735 406,-316.222 406,-303.256\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"409.5,-303.025 406,-293.025 402.5,-303.026 409.5,-303.025\"/>\n",
       "</g>\n",
       "<!-- 4631142472 -->\n",
       "<g id=\"node18\" class=\"node\"><title>4631142472</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"440.492,-440 371.508,-440 371.508,-406 440.492,-406 440.492,-440\"/>\n",
       "<text text-anchor=\"middle\" x=\"406\" y=\"-412.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (500, 500)</text>\n",
       "</g>\n",
       "<!-- 4631142472&#45;&gt;4728625496 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>4631142472&#45;&gt;4728625496</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M406,-405.885C406,-396.079 406,-383.497 406,-373.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"409.5,-373.111 406,-363.111 402.5,-373.111 409.5,-373.111\"/>\n",
       "</g>\n",
       "<!-- 4728580808 -->\n",
       "<g id=\"node19\" class=\"node\"><title>4728580808</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"558.992,-363 481.008,-363 481.008,-343 558.992,-343 558.992,-363\"/>\n",
       "<text text-anchor=\"middle\" x=\"520\" y=\"-349.4\" font-family=\"Times,serif\" font-size=\"12.00\">(60000, 500)</text>\n",
       "</g>\n",
       "<!-- 4728580808&#45;&gt;4728625264 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>4728580808&#45;&gt;4728625264</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M504.625,-342.829C485.396,-331.359 452.268,-311.598 429.764,-298.175\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"431.512,-295.142 421.131,-293.025 427.926,-301.154 431.512,-295.142\"/>\n",
       "</g>\n",
       "<!-- 4728579080 -->\n",
       "<g id=\"node20\" class=\"node\"><title>4728579080</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"642.992,-363 577.008,-363 577.008,-343 642.992,-343 642.992,-363\"/>\n",
       "<text text-anchor=\"middle\" x=\"610\" y=\"-349.4\" font-family=\"Times,serif\" font-size=\"12.00\">(500, 500)</text>\n",
       "</g>\n",
       "<!-- 4728579080&#45;&gt;4728625264 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>4728579080&#45;&gt;4728625264</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M586.975,-342.975C580.833,-340.637 574.185,-338.169 568,-336 526.446,-321.427 478.352,-306.193 445.427,-296.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"446.307,-292.618 435.719,-293.018 444.245,-299.308 446.307,-292.618\"/>\n",
       "</g>\n",
       "<!-- 4728580424 -->\n",
       "<g id=\"node21\" class=\"node\"><title>4728580424</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"553.992,-293 476.008,-293 476.008,-273 553.992,-273 553.992,-293\"/>\n",
       "<text text-anchor=\"middle\" x=\"515\" y=\"-279.4\" font-family=\"Times,serif\" font-size=\"12.00\">(60000, 500)</text>\n",
       "</g>\n",
       "<!-- 4728580424&#45;&gt;4728624336 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>4728580424&#45;&gt;4728624336</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M512.438,-272.829C509.589,-262.633 504.91,-245.887 501.271,-232.864\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"504.584,-231.715 498.522,-223.025 497.842,-233.598 504.584,-231.715\"/>\n",
       "</g>\n",
       "<!-- 4728625960 -->\n",
       "<g id=\"node22\" class=\"node\"><title>4728625960</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"683.548,-223 570.452,-223 570.452,-203 683.548,-203 683.548,-223\"/>\n",
       "<text text-anchor=\"middle\" x=\"627\" y=\"-209.4\" font-family=\"Times,serif\" font-size=\"12.00\">TransposeBackward</text>\n",
       "</g>\n",
       "<!-- 4728625960&#45;&gt;4728624104 -->\n",
       "<g id=\"edge21\" class=\"edge\"><title>4728625960&#45;&gt;4728624104</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M627,-202.829C627,-192.735 627,-176.222 627,-163.256\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"630.5,-163.025 627,-153.025 623.5,-163.026 630.5,-163.025\"/>\n",
       "</g>\n",
       "<!-- 4631144824 -->\n",
       "<g id=\"node23\" class=\"node\"><title>4631144824</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"664.492,-300 589.508,-300 589.508,-266 664.492,-266 664.492,-300\"/>\n",
       "<text text-anchor=\"middle\" x=\"627\" y=\"-272.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (2000, 500)</text>\n",
       "</g>\n",
       "<!-- 4631144824&#45;&gt;4728625960 -->\n",
       "<g id=\"edge22\" class=\"edge\"><title>4631144824&#45;&gt;4728625960</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M627,-265.885C627,-256.079 627,-243.497 627,-233.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"630.5,-233.111 627,-223.111 623.5,-233.111 630.5,-233.111\"/>\n",
       "</g>\n",
       "<!-- 4728581064 -->\n",
       "<g id=\"node24\" class=\"node\"><title>4728581064</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"779.992,-223 702.008,-223 702.008,-203 779.992,-203 779.992,-223\"/>\n",
       "<text text-anchor=\"middle\" x=\"741\" y=\"-209.4\" font-family=\"Times,serif\" font-size=\"12.00\">(60000, 500)</text>\n",
       "</g>\n",
       "<!-- 4728581064&#45;&gt;4728624104 -->\n",
       "<g id=\"edge23\" class=\"edge\"><title>4728581064&#45;&gt;4728624104</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M725.625,-202.829C706.396,-191.359 673.268,-171.598 650.764,-158.175\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"652.512,-155.142 642.131,-153.025 648.926,-161.154 652.512,-155.142\"/>\n",
       "</g>\n",
       "<!-- 4728580360 -->\n",
       "<g id=\"node25\" class=\"node\"><title>4728580360</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"869.992,-223 798.008,-223 798.008,-203 869.992,-203 869.992,-223\"/>\n",
       "<text text-anchor=\"middle\" x=\"834\" y=\"-209.4\" font-family=\"Times,serif\" font-size=\"12.00\">(500, 2000)</text>\n",
       "</g>\n",
       "<!-- 4728580360&#45;&gt;4728624104 -->\n",
       "<g id=\"edge24\" class=\"edge\"><title>4728580360&#45;&gt;4728624104</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M808.82,-202.892C802.372,-200.603 795.441,-198.178 789,-196 747.032,-181.807 698.633,-166.396 665.745,-156.065\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"666.649,-152.681 656.06,-153.029 664.555,-159.361 666.649,-152.681\"/>\n",
       "</g>\n",
       "<!-- 4728578824 -->\n",
       "<g id=\"node26\" class=\"node\"><title>4728578824</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"780.992,-153 697.008,-153 697.008,-133 780.992,-133 780.992,-153\"/>\n",
       "<text text-anchor=\"middle\" x=\"739\" y=\"-139.4\" font-family=\"Times,serif\" font-size=\"12.00\">(60000, 2000)</text>\n",
       "</g>\n",
       "<!-- 4728578824&#45;&gt;4728624568 -->\n",
       "<g id=\"edge25\" class=\"edge\"><title>4728578824&#45;&gt;4728624568</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M736.303,-132.829C733.304,-122.633 728.379,-105.887 724.548,-92.864\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"727.834,-91.6315 721.655,-83.0255 721.119,-93.6068 727.834,-91.6315\"/>\n",
       "</g>\n",
       "<!-- 4728544504 -->\n",
       "<g id=\"node27\" class=\"node\"><title>4728544504</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"906.548,-83 793.452,-83 793.452,-63 906.548,-63 906.548,-83\"/>\n",
       "<text text-anchor=\"middle\" x=\"850\" y=\"-69.4\" font-family=\"Times,serif\" font-size=\"12.00\">TransposeBackward</text>\n",
       "</g>\n",
       "<!-- 4728544504&#45;&gt;4728544272 -->\n",
       "<g id=\"edge26\" class=\"edge\"><title>4728544504&#45;&gt;4728544272</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M850,-62.9992C850,-54.4396 850,-41.2833 850,-30.3462\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"853.5,-30.0377 850,-20.0377 846.5,-30.0377 853.5,-30.0377\"/>\n",
       "</g>\n",
       "<!-- 4631143368 -->\n",
       "<g id=\"node28\" class=\"node\"><title>4631143368</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"881.492,-160 818.508,-160 818.508,-126 881.492,-126 881.492,-160\"/>\n",
       "<text text-anchor=\"middle\" x=\"850\" y=\"-132.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (3, 2000)</text>\n",
       "</g>\n",
       "<!-- 4631143368&#45;&gt;4728544504 -->\n",
       "<g id=\"edge27\" class=\"edge\"><title>4631143368&#45;&gt;4728544504</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M850,-125.885C850,-116.079 850,-103.497 850,-93.1799\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"853.5,-93.1112 850,-83.1112 846.5,-93.1113 853.5,-93.1112\"/>\n",
       "</g>\n",
       "<!-- 4728578248 -->\n",
       "<g id=\"node29\" class=\"node\"><title>4728578248</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"1008.99,-83 925.008,-83 925.008,-63 1008.99,-63 1008.99,-83\"/>\n",
       "<text text-anchor=\"middle\" x=\"967\" y=\"-69.4\" font-family=\"Times,serif\" font-size=\"12.00\">(60000, 2000)</text>\n",
       "</g>\n",
       "<!-- 4728578248&#45;&gt;4728544272 -->\n",
       "<g id=\"edge28\" class=\"edge\"><title>4728578248&#45;&gt;4728544272</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M949.736,-62.9992C930.381,-52.9078 898.771,-36.4276 876.329,-24.727\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"877.82,-21.5573 867.335,-20.0377 874.584,-27.7643 877.82,-21.5573\"/>\n",
       "</g>\n",
       "<!-- 4728580296 -->\n",
       "<g id=\"node30\" class=\"node\"><title>4728580296</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"1086.99,-83 1027.01,-83 1027.01,-63 1086.99,-63 1086.99,-83\"/>\n",
       "<text text-anchor=\"middle\" x=\"1057\" y=\"-69.4\" font-family=\"Times,serif\" font-size=\"12.00\">(2000, 3)</text>\n",
       "</g>\n",
       "<!-- 4728580296&#45;&gt;4728544272 -->\n",
       "<g id=\"edge29\" class=\"edge\"><title>4728580296&#45;&gt;4728544272</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1036.14,-62.8666C1030.32,-60.4789 1023.96,-58.0128 1018,-56 978.72,-42.7423 933.251,-30.7617 899.529,-22.5017\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"900.004,-19.0154 889.46,-20.0604 898.354,-25.8183 900.004,-19.0154\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x11409aac8>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.DoubleTensor'> <class 'torch.DoubleTensor'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "torch.FloatTensor constructor received an invalid combination of arguments - got (torch.DoubleTensor), but expected one of:\n * no arguments\n * (int ...)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (torch.FloatTensor viewed_tensor)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (torch.Size size)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (torch.FloatStorage data)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (Sequence data)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-e8e1635f79fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.FloatTensor constructor received an invalid combination of arguments - got (torch.DoubleTensor), but expected one of:\n * no arguments\n * (int ...)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (torch.FloatTensor viewed_tensor)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (torch.Size size)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (torch.FloatStorage data)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n * (Sequence data)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.DoubleTensor\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(data_loader):\n",
    "    x, y = batch\n",
    "    x_var = autograd.Variable(torch.Tensor(x), requires_grad=False)\n",
    "    y_var = autograd.Variable(torch.Tensor(y), requires_grad=False)\n",
    "    print(type(x_var))\n",
    "   \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = autograd.Variable(torch.rand(5,3))\n",
    "y = autograd.Variable(torch.rand(5,3))\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Variable' object has no attribute 'creator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-a6571e6541ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/hxiong/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fallthrough_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Variable' object has no attribute 'creator'"
     ]
    }
   ],
   "source": [
    "z.creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.2976  0.5228  0.2717\n",
      " 0.7981  0.1206  0.1279\n",
      " 0.7825  0.2150  0.1564\n",
      " 0.6082  0.8017  0.3107\n",
      " 0.4840  0.9581  0.1413\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.2976  0.7981  0.7825  0.6082  0.4840\n",
       " 0.5228  0.1206  0.2150  0.8017  0.9581\n",
       " 0.2717  0.1279  0.1564  0.3107  0.1413\n",
       "[torch.FloatTensor of size 3x5]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = torch.transpose(x, 0, 1)\n",
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.4357  0.3353  0.3878  0.6845  0.6833\n",
       " 0.3353  0.6679  0.6704  0.6218  0.5199\n",
       " 0.3878  0.6704  0.6829  0.6969  0.6068\n",
       " 0.6845  0.6218  0.6969  1.1092  1.1064\n",
       " 0.6833  0.5199  0.6068  1.1064  1.1722\n",
       "[torch.FloatTensor of size 5x5]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_p = torch.matmul(x, x_t)\n",
    "dot_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.3128  1.4680  1.4704  1.4436  1.3089\n",
       " 1.4680  0.7575  0.8597  1.5236  1.5901\n",
       " 1.4704  0.8597  0.9419  1.4808  1.5236\n",
       " 1.4436  1.5236  1.4808  1.2229  1.0913\n",
       " 1.3089  1.5901  1.5236  1.0913  0.8224\n",
       "[torch.FloatTensor of size 5x5]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_x + sum_x_t - 2 * dot_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.0921\n",
       " 1.0466\n",
       " 1.1539\n",
       " 1.7206\n",
       " 1.5834\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_x = torch.sum(x, 1)\n",
    "sum_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.0921\n",
       " 1.0466\n",
       " 1.1539\n",
       " 1.7206\n",
       " 1.5834\n",
       "[torch.FloatTensor of size 5x1]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_x_t = sum_x.view([-1, 1])\n",
    "sum_x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2.1841  2.1387  2.2460  2.8127  2.6754\n",
       " 2.1387  2.0932  2.2005  2.7672  2.6300\n",
       " 2.2460  2.2005  2.3078  2.8745  2.7373\n",
       " 2.8127  2.7672  2.8745  3.4412  3.3040\n",
       " 2.6754  2.6300  2.7373  3.3040  3.1668\n",
       "[torch.FloatTensor of size 5x5]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_x + sum_x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = x.pow(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.50012794, -1.22640167, -0.81446661],\n",
       "       [ 0.96948341,  0.09616873, -0.4705303 ],\n",
       "       [-0.9061921 , -0.44259913,  0.19639915],\n",
       "       [ 0.97974426, -1.09530965, -0.54107082],\n",
       "       [-1.79419994, -0.64490507,  1.12364734]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = np.random.randn(5,3)\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.2506397 ,  1.50406105,  0.66335586],\n",
       "       [ 0.93989808,  0.00924842,  0.22139877],\n",
       "       [ 0.82118413,  0.19589399,  0.03857263],\n",
       "       [ 0.95989881,  1.19970324,  0.29275763],\n",
       "       [ 3.21915342,  0.41590255,  1.26258334]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy = np.square(xx)\n",
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.50012794, -1.22640167, -0.81446661],\n",
       "       [ 0.96948341,  0.09616873, -0.4705303 ],\n",
       "       [-0.9061921 , -0.44259913,  0.19639915],\n",
       "       [ 0.97974426, -1.09530965, -0.54107082],\n",
       "       [-1.79419994, -0.64490507,  1.12364734]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.0921\n",
       " 1.0466\n",
       " 1.1539\n",
       " 1.7206\n",
       " 1.5834\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q = sum_x + sum_x.view([-1, 1]) - 2 * torch.matmul(x, torch.transpose(x, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.3128  1.4680  1.4704  1.4436  1.3089\n",
       " 1.4680  0.7575  0.8597  1.5236  1.5901\n",
       " 1.4704  0.8597  0.9419  1.4808  1.5236\n",
       " 1.4436  1.5236  1.4808  1.2229  1.0913\n",
       " 1.3089  1.5901  1.5236  1.0913  0.8224\n",
       "[torch.FloatTensor of size 5x5]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = Q/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q = 1 + Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  0  0  0  0\n",
       " 0  1  0  0  0\n",
       " 0  0  1  0  0\n",
       " 0  0  0  1  0\n",
       " 0  0  0  0  1\n",
       "[torch.FloatTensor of size 5x5]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0  1  1  1  1\n",
       " 1  0  1  1  1\n",
       " 1  1  0  1  1\n",
       " 1  1  1  0  1\n",
       " 1  1  1  1  0\n",
       "[torch.FloatTensor of size 5x5]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_dgnl_mat = autograd.Variable(1-torch.eye(5), requires_grad=False)\n",
    "zero_dgnl_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2.3128  2.4680  2.4704  2.4436  2.3089\n",
       " 2.4680  1.7575  1.8597  2.5236  2.5901\n",
       " 2.4704  1.8597  1.9419  2.4808  2.5236\n",
       " 2.4436  2.5236  2.4808  2.2229  2.0913\n",
       " 2.3089  2.5901  2.5236  2.0913  1.8224\n",
       "[torch.FloatTensor of size 5x5]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = autograd.Variable(Q, requires_grad=False)\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0000  2.4680  2.4704  2.4436  2.3089\n",
       " 2.4680  0.0000  1.8597  2.5236  2.5901\n",
       " 2.4704  1.8597  0.0000  2.4808  2.5236\n",
       " 2.4436  2.5236  2.4808  0.0000  2.0913\n",
       " 2.3089  2.5901  2.5236  2.0913  0.0000\n",
       "[torch.FloatTensor of size 5x5]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = Q * zero_dgnl_mat\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.0249\n",
       " 0.9907\n",
       " 0.9772\n",
       " 1.0050\n",
       " 1.0022\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_row = torch.sum(Q, 1)\n",
    "sum_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0000  0.2614  0.2647  0.2562  0.2427\n",
       " 0.2547  0.0000  0.1992  0.2645  0.2722\n",
       " 0.2549  0.1970  0.0000  0.2601  0.2653\n",
       " 0.2522  0.2673  0.2658  0.0000  0.2198\n",
       " 0.2382  0.2743  0.2704  0.2192  0.0000\n",
       "[torch.FloatTensor of size 5x5]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = Q / sum_row\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(Q, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.83883826,  0.56122471,  0.80961847,  0.98022598,  0.9134492 ],\n",
       "       [ 0.86461802,  0.0839184 ,  0.415856  ,  0.09671539,  0.43589492],\n",
       "       [ 0.90210869,  0.33500608,  0.44111305,  0.5495927 ,  0.55802914],\n",
       "       [ 0.26455514,  0.23790882,  0.91743497,  0.62991718,  0.48389179],\n",
       "       [ 0.65505091,  0.11537323,  0.55665203,  0.57175657,  0.16476388]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_x = np.random.rand(5,5)\n",
    "tst_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04734479,  0.75258951,  0.80395799,  0.68955919,  0.04641471])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_v = np.random.rand(5)\n",
    "tst_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,5) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-b79d85653e89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtst_x\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtst_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,5) (4,) "
     ]
    }
   ],
   "source": [
    "tst_x / tst_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10e-4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
